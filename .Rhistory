H <- ReIns::Hill(secura$Loss, k = TRUE,
lwd = 2, plot = TRUE, main = "")
# Chunk 73
H <- ReIns::Hill(secura$Loss, k = TRUE, lwd = 2, plot = TRUE, main = "")
# Chunk 75
H <- ReIns::Hill(secura$Loss, lwd = 2, plot = TRUE, main = "")
kopt <- ReIns::Hill.kopt(secura$Loss, plot = FALSE)$kopt
abline(v = kopt, lwd = 2, lty = 2)
# Chunk 76
# sample size
n <- length(secura$Loss)
n
# Hill estimator
kopt <- Hill.kopt(secura$Loss, plot = FALSE)$kopt
kopt
# chosen threshold
threshold <- sort(secura$Loss)[n - kopt]
threshold
# estimate for gamma using Hill estimator
gamma <- H$gamma[kopt]
gamma
# Chunk 77
threshold
# Chunk 78
gamma
# Chunk 79
(p <- sum(secura$Loss <= threshold)/n)
# Chunk 80
(n-kopt)/n
# Chunk 81
sh <- 1200000 # shift
I <- secura$Loss <= threshold # indicator
neg.loglik <- function(par) {
lambda <- exp(par[1]); alpha <- exp(par[2])
# likelihood
L <- I * (n-kopt)/n * lambda * exp(-lambda*(secura$Loss-sh))/(1 - exp(-lambda*(threshold-sh))) +
(1-I) * kopt/n * alpha * (secura$Loss)^(-alpha-1)/(threshold)^(-alpha)
# negative log-likelihood
-sum(log(L))
}
m1 <- mean(secura$Loss)
par.init <- c(1/(m1-sh), 1/m1)
oo <- nlm(neg.loglik, log(par.init))
(lambda <- exp(oo$estimate[1]))
(alpha <- exp(oo$estimate[2]))
(gamma <- 1/alpha)
# Chunk 82
# CDF for Exp-Pa splicing model
ExpPa_cdf <- function(x, sh, threshold, lambda, gamma) {
p <- numeric(length(x))
p[x <= threshold] <- (n - kopt) / n * pexp(x[x <= threshold] - sh, rate = lambda) /
pexp(threshold - sh, rate = lambda)
p[x > threshold] <- 1 - kopt / n * (x[x > threshold] / threshold) ^ (-1/gamma)
return(p)
}
# Chunk 83
# Plot empirical CDF and fitted CDF
plot(ecdf(secura$Loss), do.points = FALSE, xlab = "CDF", xlim = c(sh, 7 * 10^6), lwd=2)
lines(sort(secura$Loss), ExpPa_cdf(sort(secura$Loss), sh, threshold, lambda, gamma), lty = 2, lwd=2)
legend("bottomright", c("Empirical CDF", "Fitted CDF"), lty = c(1, 2), lwd = 2)
# Chunk 84
# Fit ME model using internal function from
# ReIns package
MEfit_sec <- ReIns:::.ME_tune(secura$Loss,
trunclower = sh,
criterium = "BIC",
M = 10,
s = 1:40)$best_model
# Fitted parameters
MEfit_sec$alpha
MEfit_sec$shape
MEfit_sec$theta
# Chunk 85
# Histogram
truehist(secura$Loss, nbins = 40, ylim = c(0, 8e-07), xlab = "Claim size", ylab = "Density")
curve(ReIns:::.ME_density(x, theta = MEfit_sec$theta, shape = MEfit_sec$shape,
alpha = MEfit_sec$alpha, trunclower = sh),
from = 10^6, to = 8 * 10^06, n = 10000, add = TRUE, col = "red", lwd = 2)
legend('topright', legend = c("ME Density", "Observed Relative Frequency"),
col = c("red", "cyan"), pch = c(NA,15), pt.cex = 2, lty = c(1,NA), lwd = c(2,NA))
# Chunk 87
ME_VaR <- Vectorize(ReIns:::.ME_VaR, vectorize.args = "p")
# QQ-plot
plot(ME_VaR((1:n) / (n+1), theta = MEfit_sec$theta, shape = MEfit_sec$shape, alpha = MEfit_sec$alpha, trunclower = sh),
sort(secura$Loss), main = "ME QQ-plot", xlab = "Fitted quantiles", ylab = "Empirical quantiles")
abline(0, 1)
# Chunk 89
# Fit ME-Pa splicing model
splicefit_sec <- SpliceFitPareto(secura$Loss, tsplice = threshold, M = 10, trunclower = sh)
# Summary
summary(splicefit_sec)
# Chunk 91
# ECDF plot
x <- seq(10^6, 10^7, 10^3)
SpliceECDF(x, secura$Loss, splicefit_sec, lwd = 2)
abline(v = splicefit_sec$t, lty = 2, lwd = 2)
# Zoomed ECDF plot
# SpliceECDF(x, secura$Loss, splicefit_sec, lwd = 2, ylim = c(0,0.3))
# abline(v = splicefit_sec$t, lty = 2, lwd = 2)
# Chunk 93
# Zoomed ECDF plot
SpliceECDF(x, secura$Loss, splicefit_sec, lwd = 2, ylim = c(0,0.3))
abline(v = splicefit_sec$t, lty = 2, lwd = 2)
# Chunk 95
# PP-plot
SplicePP(secura$Loss, splicefit_sec)
# Chunk 96
# PP-plot with minus log-scale
SplicePP(secura$Loss, splicefit_sec, log = TRUE)
# Chunk 98
# QQ-plot
SpliceQQ(secura$Loss, splicefit_sec)
# Chunk 99
# Quantile function for Exp-Pa splicing model
ExpPa_quantile <- function(p, sh, threshold, lambda, gamma) {
pi <- (n-kopt)/n
x <- numeric(length(p))
x[p <= pi] <- qexp(p[p <= pi] / pi * (pexp(threshold, rate = lambda) - pexp(sh, rate = lambda)) +
pexp(sh, rate = lambda), rate = lambda)
x[p > pi] <- threshold * (1 - (p[p > pi] - pi) / (1-pi))^(-gamma)
return(x)
}
# Chunk 100
ExpPa_quantile(0.95, sh, threshold, lambda, gamma)
setwd("C:/Users/u0110176/Dropbox/Cursus Arcturus/Dag1/Material")
qf <- function(p) {
ExpPa_quantile(p, sh, threshold, lambda, gamma)
}
integrate(qf, lower = 0.95, upper = 1)
# Chunk 1: setup
options(htmltools.dir.version = FALSE)
library(knitr)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
# options(knitr.table.format = "html")
library(tidyverse)
library(fontawesome) # from github: https://github.com/rstudio/fontawesome
library(DiagrammeR)
library(emo) # from github: https://github.com/hadley/emo
library(gt) # from github: https://github.com/rstudio/gt
library(countdown) # from github: https://github.com/gadenbuie/countdown
library(here)
# Chunk 2: setup_greenwell
# Set global R options
options(htmltools.dir.version = FALSE, servr.daemon = TRUE,
crayon.enabled = TRUE)
# Set global knitr chunk options
knitr::opts_chunk$set(
dev = "svg",
fig.align = "center",
cache = TRUE,
error = FALSE,
message = FALSE,
warning = FALSE,
collapse = TRUE
)
# colors - I copied most of these from # https://github.com/edrubin/EC524W20
dark2 <- RColorBrewer::brewer.pal(8, name = "Dark2")
KULbg <- "#116E8A"
red_pink   = "#e64173"
turquoise  = "#20B2AA"
orange     = "#FFA500"
red        = "#fb6107"
blue       = "#3b3b9a"
green      = "#8bb174"
grey_light = "grey70"
grey_mid   = "grey50"
grey_dark  = "grey20"
purple     = "#6A5ACD"
slate      = "#314f4f"
# Chunk 3
library(tidyverse)
# Chunk 7
# install.packages("here")
library(here)
dir <- here::here()
#setwd(dir)
mtpl_orig <- read.table('./data/PC_data.txt',
header = TRUE)
mtpl_orig <- as_tibble(mtpl_orig)
# Chunk 8
str(mtpl_orig)
# Chunk 9
head(mtpl_orig) %>% kable(format = 'html')
# Chunk 10
mtpl_orig %>% slice(1:3) %>% select(-LONG, -LAT) %>% kable(format = 'html')
# Chunk 12: prepare-mtpl
mtpl <- mtpl_orig %>%
# rename all columns
rename_all(function(.name) {
.name %>%
# replace all names with the lowercase versions
tolower
# replace all spaces with underscores is also useful, with `str_replace(" ", "-")`
})
mtpl <- rename(mtpl, expo = exp)
# Chunk 14
dim(mtpl)
# Chunk 16
mtpl %>% summarize(emp_freq = sum(nclaims) / sum(expo)) %>% kable(format = 'html')
# Chunk 18
mtpl %>%
group_by(sex) %>%
summarize(emp_freq = sum(nclaims) / sum(expo)) %>% kable(format = "html")
# Chunk 20
KULbg <- "#116E8A"
g <- ggplot(mtpl, aes(nclaims)) + theme_bw() +
geom_bar(aes(weight = expo), col = KULbg,
fill = KULbg, alpha = 0.5) +
labs(y = "Abs freq (in exposure)") +
ggtitle("MTPL - number of claims")
g
# Chunk 22
g <- ggplot(mtpl, aes(nclaims)) + theme_bw() +
geom_bar(aes(weight = expo), col = KULbg,
fill = KULbg, alpha = 0.5) +
labs(y = "Abs freq (in exposure)") +
ggtitle("MTPL - number of claims")
g
# Chunk 24
g <- ggplot(mtpl, aes(nclaims)) + theme_bw()
g + geom_bar(aes(y = (..count..)/sum(..count..)),
col = KULbg, fill = KULbg, alpha = 0.5) +
labs(y = "Relative frequency") +
ggtitle("MTPL - relative number of claims")
# Chunk 26
g_dens <- mtpl %>% filter(avg > 0 & avg <= 81000) %>% ggplot(aes(x = avg)) + theme_bw() +
geom_density(adjust = 3, col = KULbg, fill = KULbg, alpha = 0.5) + xlim(0, 1e4) + ylab("") + xlab("severity") +
ggtitle("MTPL data - average amount per claim")
g_dens
# Chunk 28
g <- mtpl %>% filter(avg > 0 & avg <= 81000) %>% ggplot(aes(x = avg)) + theme_bw() + xlab("severity") +
geom_histogram(binwidth = 100, col = KULbg,
fill = KULbg, alpha = 0.5) + xlim(0, 1e4) +
labs(y = "Frequency histogram")
g
# Chunk 29
secura <- read.table(file="./data/SecuraRe.txt",
header = TRUE, sep = "\t")
# Chunk 30
require(gridExtra)
grid.arrange(
ggplot(secura, aes(Loss)) +
theme_bw() +
geom_density(col = KULbg, fill = KULbg, alpha = 0.5) +
ggtitle('Secura Re - losses') + xlab('loss') + ylab(''),
ggplot(secura, aes(log(Loss))) +
theme_bw() +
geom_density(col = KULbg, fill = KULbg, alpha = 0.5) +
ggtitle('Secura Re  - losses, log-scale') + xlab('log(loss)') + ylab(''))
# Chunk 32
ggplot(secura, aes(Year, Loss)) + theme_bw() + geom_point(colour = KULbg, size = 2, alpha = 0.5) +
ggtitle('Secura Re - losses arriving over time')
# Chunk 34
empirical <- mtpl$nclaims %>%
table %>% prop.table %>% as.numeric
# Chunk 35
k <- 1:(length(empirical) - 1)
ab0_relation <- empirical[k+1] / empirical[k] * k
# Chunk 36
ab0_data <- tibble(k = k, ab0_rel = ab0_relation)
# Chunk 38
empirical <- mtpl$nclaims %>%
table %>% prop.table %>% as.numeric
k <- 1:(length(empirical)-1)
ab0_relation <- empirical[k+1] / empirical[k] * k
ggplot(data.frame(k = k, relation = ab0_relation),
aes(x = k, y = relation)) +
theme_bw() + ylab('frac') +
geom_point() +
geom_smooth(method = 'lm', se = FALSE)
# Chunk 40
mean(mtpl$nclaims)
sum(mtpl$nclaims)/sum(mtpl$expo)
weighted.mean(mtpl$nclaims/mtpl$expo, mtpl$expo)
mtpl %>% summarize(emp_freq = sum(nclaims) / sum(expo)) %>% kable(format = 'html')
# Chunk 41
m <- sum(mtpl$nclaims)/sum(mtpl$expo)
m
var <- sum((mtpl$nclaims - m * mtpl$expo)^2)/
sum(mtpl$expo)
var
# Chunk 42
library(MASS)
fitdistr(mtpl$nclaims, "poisson")
# Chunk 45
freq_glm_poi <- glm(nclaims ~ 1, offset = log(expo),
family = poisson(link = "log"),
data = mtpl)
freq_glm_poi %>% broom::tidy() %>% kable(format = 'html')
# Chunk 47
neg_loglik_pois <- function(par, freq, expo){
lambda <- expo*exp(par)
-sum(dpois(freq, lambda, log = T))
}
sol_poi <- nlm(neg_loglik_pois, 1, hessian = TRUE,
freq = mtpl$nclaims, expo = mtpl$expo)
# Chunk 48
exp(sol_poi$estimate)
sqrt(diag(solve(sol_poi$hessian)))
sol_poi$minimum
# Chunk 50
freq_glm_nb <- glm.nb(nclaims ~ 1 + offset(log(expo)),
link = log,
data = mtpl)
freq_glm_nb %>% broom::tidy() %>% kable(format = 'html')
# Chunk 51
freq_glm_nb$theta
freq_glm_nb$SE.theta
# Chunk 52
summary(freq_glm_nb)
# Chunk 53
neg_loglik_nb <- function(par, freq, expo){
mu <- expo*exp(par[1])
r <- exp(par[2])
-sum(dnbinom(freq, size = r, mu = mu, log = TRUE))
}
sol_nb <- nlm(neg_loglik_nb, c(1, 1), hessian = TRUE,
freq = mtpl$nclaims, expo = mtpl$expo)
# Chunk 54
sol_nb$estimate
# Chunk 55
exp(sol_nb$estimate)
sqrt(diag(solve(sol_nb$hessian)))
sol_nb$minimum
# Chunk 56
exp(sol_nb$estimate[1]) +
(exp(sol_nb$estimate[1])^2)/(exp(sol_nb$estimate[2]))
# Chunk 57
AIC_poi <- 2*length(sol_poi$estimate) + 2*sol_poi$minimum
AIC_nb <- 2*length(sol_nb$estimate) + 2*sol_nb$minimum
c(AIC_nb = AIC_nb, AIC_poi = AIC_poi)
# Chunk 58
observed_count = rep(0, 5)
model_based_count = rep(0, 5)
for(i in 1:5) {
observed_count[i] = sum(mtpl$nclaims == i-1)
model_based_count[i] = sum(dnbinom(i-1, size = freq_glm_nb$theta, mu = fitted(freq_glm_nb)))
}
data.frame(frequency = 0:4,
observed_count = observed_count,
model_based_count = round(model_based_count))
# Chunk 59
library(pscl)
f_ZIP <- zeroinfl(nclaims ~ 1, offset = log(expo),
dist = "poisson", data = mtpl)
summary(f_ZIP)
# Chunk 60
f_ZIP$coefficients
(f_ZIP_lambda <- exp(as.numeric(f_ZIP$coefficients[1])))
(f_ZIP_pi <- exp(as.numeric(f_ZIP$coefficients[2]))/(1+exp(as.numeric(f_ZIP$coefficients[2]))))
(AIC_ZIP <- 2*length(f_ZIP$coefficients) - 2*f_ZIP$loglik)
# Chunk 61
(ZIP_mean <- (1-f_ZIP_pi)*f_ZIP_lambda)
(ZIP_var <- (1-f_ZIP_pi)*f_ZIP_lambda*(1+f_ZIP_pi*f_ZIP_lambda))
# Chunk 62
neg_loglik_ZIP <- function(par, freq, expo){
lambda <- expo*exp(par[1])
p <- exp(par[2])/(1+exp(par[2]))
-sum((freq == 0) * (log(p + (1-p)*dpois(0, lambda, log = FALSE)))) -
sum((freq != 0) * (log((1-p)) + dpois(freq, lambda, log = TRUE)))
}
sol_ZIP <- nlm(neg_loglik_ZIP, c(1, 1), hessian = TRUE,
freq = mtpl$nclaims, expo = mtpl$expo)
sol_ZIP$estimate
# Chunk 63
(sol_ZIP_se <- sqrt(diag(solve(sol_ZIP$hessian))))
# Chunk 65
library(ReIns)
ReIns::MeanExcess(secura$Loss)
#abline(v = 2.6 * 10^6, lwd = 2, lty = 2)
# Chunk 67
ReIns::ExpQQ(secura$Loss)
# Chunk 69
ReIns::ParetoQQ(secura$Loss)
# Chunk 70
H <- ReIns::Hill(secura$Loss, k = FALSE,
lwd = 2, plot = TRUE, main = "")
# Chunk 71
H <- ReIns::Hill(secura$Loss, k = FALSE, lwd = 2, plot = TRUE, main = "")
# Chunk 72
H <- ReIns::Hill(secura$Loss, k = TRUE,
lwd = 2, plot = TRUE, main = "")
# Chunk 73
H <- ReIns::Hill(secura$Loss, k = TRUE, lwd = 2, plot = TRUE, main = "")
# Chunk 75
H <- ReIns::Hill(secura$Loss, lwd = 2, plot = TRUE, main = "")
kopt <- ReIns::Hill.kopt(secura$Loss, plot = FALSE)$kopt
abline(v = kopt, lwd = 2, lty = 2)
# Chunk 76
# sample size
n <- length(secura$Loss)
n
# Hill estimator
kopt <- Hill.kopt(secura$Loss, plot = FALSE)$kopt
kopt
# chosen threshold
threshold <- sort(secura$Loss)[n - kopt]
threshold
# estimate for gamma using Hill estimator
gamma <- H$gamma[kopt]
gamma
# Chunk 77
threshold
# Chunk 78
gamma
# Chunk 79
(p <- sum(secura$Loss <= threshold)/n)
# Chunk 80
(n-kopt)/n
# Chunk 81
sh <- 1200000 # shift
I <- secura$Loss <= threshold # indicator
neg.loglik <- function(par) {
lambda <- exp(par[1]); alpha <- exp(par[2])
# likelihood
L <- I * (n-kopt)/n * lambda * exp(-lambda*(secura$Loss-sh))/(1 - exp(-lambda*(threshold-sh))) +
(1-I) * kopt/n * alpha * (secura$Loss)^(-alpha-1)/(threshold)^(-alpha)
# negative log-likelihood
-sum(log(L))
}
m1 <- mean(secura$Loss)
par.init <- c(1/(m1-sh), 1/m1)
oo <- nlm(neg.loglik, log(par.init))
(lambda <- exp(oo$estimate[1]))
(alpha <- exp(oo$estimate[2]))
(gamma <- 1/alpha)
# Chunk 82
# CDF for Exp-Pa splicing model
ExpPa_cdf <- function(x, sh, threshold, lambda, gamma) {
p <- numeric(length(x))
p[x <= threshold] <- (n - kopt) / n * pexp(x[x <= threshold] - sh, rate = lambda) /
pexp(threshold - sh, rate = lambda)
p[x > threshold] <- 1 - kopt / n * (x[x > threshold] / threshold) ^ (-1/gamma)
return(p)
}
# Chunk 83
# Plot empirical CDF and fitted CDF
plot(ecdf(secura$Loss), do.points = FALSE, xlab = "CDF", xlim = c(sh, 7 * 10^6), lwd=2)
lines(sort(secura$Loss), ExpPa_cdf(sort(secura$Loss), sh, threshold, lambda, gamma), lty = 2, lwd=2)
legend("bottomright", c("Empirical CDF", "Fitted CDF"), lty = c(1, 2), lwd = 2)
# Chunk 84
# Fit ME model using internal function from
# ReIns package
MEfit_sec <- ReIns:::.ME_tune(secura$Loss,
trunclower = sh,
criterium = "BIC",
M = 10,
s = 1:40)$best_model
# Fitted parameters
MEfit_sec$alpha
MEfit_sec$shape
MEfit_sec$theta
# Chunk 85
# Histogram
truehist(secura$Loss, nbins = 40, ylim = c(0, 8e-07), xlab = "Claim size", ylab = "Density")
curve(ReIns:::.ME_density(x, theta = MEfit_sec$theta, shape = MEfit_sec$shape,
alpha = MEfit_sec$alpha, trunclower = sh),
from = 10^6, to = 8 * 10^06, n = 10000, add = TRUE, col = "red", lwd = 2)
legend('topright', legend = c("ME Density", "Observed Relative Frequency"),
col = c("red", "cyan"), pch = c(NA,15), pt.cex = 2, lty = c(1,NA), lwd = c(2,NA))
# Chunk 87
ME_VaR <- Vectorize(ReIns:::.ME_VaR, vectorize.args = "p")
# QQ-plot
plot(ME_VaR((1:n) / (n+1), theta = MEfit_sec$theta, shape = MEfit_sec$shape, alpha = MEfit_sec$alpha, trunclower = sh),
sort(secura$Loss), main = "ME QQ-plot", xlab = "Fitted quantiles", ylab = "Empirical quantiles")
abline(0, 1)
# Chunk 89
# Fit ME-Pa splicing model
splicefit_sec <- SpliceFitPareto(secura$Loss, tsplice = threshold, M = 10, trunclower = sh)
# Summary
summary(splicefit_sec)
# Chunk 91
# ECDF plot
x <- seq(10^6, 10^7, 10^3)
SpliceECDF(x, secura$Loss, splicefit_sec, lwd = 2)
abline(v = splicefit_sec$t, lty = 2, lwd = 2)
# Zoomed ECDF plot
# SpliceECDF(x, secura$Loss, splicefit_sec, lwd = 2, ylim = c(0,0.3))
# abline(v = splicefit_sec$t, lty = 2, lwd = 2)
# Chunk 93
# Zoomed ECDF plot
SpliceECDF(x, secura$Loss, splicefit_sec, lwd = 2, ylim = c(0,0.3))
abline(v = splicefit_sec$t, lty = 2, lwd = 2)
# Chunk 95
# PP-plot
SplicePP(secura$Loss, splicefit_sec)
# Chunk 96
# PP-plot with minus log-scale
SplicePP(secura$Loss, splicefit_sec, log = TRUE)
# Chunk 98
# QQ-plot
SpliceQQ(secura$Loss, splicefit_sec)
# Chunk 99
# Quantile function for Exp-Pa splicing model
ExpPa_quantile <- function(p, sh, threshold, lambda, gamma) {
pi <- (n-kopt)/n
x <- numeric(length(p))
x[p <= pi] <- qexp(p[p <= pi] / pi * (pexp(threshold, rate = lambda) - pexp(sh, rate = lambda)) +
pexp(sh, rate = lambda), rate = lambda)
x[p > pi] <- threshold * (1 - (p[p > pi] - pi) / (1-pi))^(-gamma)
return(x)
}
# Chunk 100
ExpPa_quantile(0.95, sh, threshold, lambda, gamma)
qf <- function(p) {
ExpPa_quantile(p, sh, threshold, lambda, gamma)
}
integrate(qf, lower = 0.95, upper = 1)
integrate(qf, lower = 0.95, upper = 1) / 0.05
int <- integrate(qf, lower = 0.95, upper = 1)
str(int)
int$value / 0.05
